{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Forest Coverage Type to Predict Ecological Shifts\n",
    "\n",
    "by: Carter Koehler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Description and Prediction Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset contains information on the forest coverage types from the Roosevelt National Forest in Colorado. The data consists of $12$ explanatory variables related to cartographic measurements of a particular area and a categorical encoding of what type of tree cover that area has. In particular, it has features on:\n",
    "\n",
    "- elevation\n",
    "- grade of slope (slope)\n",
    "- direction of slope (aspect)\n",
    "- distance to water\n",
    "- distance to roads\n",
    "- distance to fire points\n",
    "- shade coverage at various times in the day\n",
    "- wilderness area\n",
    "- soil type\n",
    "\n",
    "All of the categorical data (with the exception of the target variable) has already been one-hot encoded, meaning the the data we are dealing with already has quite a few more than $12$ columns.\n",
    "\n",
    "All of this is well and good, but it begs the question why we would want to be able to predict the forest coverage of a particular block of forest. One possible application is as follows: If it happens that we are able to predict how a particular area of forest is covered, this gives us a good qualitative description of what flora is present in that area. However, if the cartographic features of that area were to change due to human or other influence, such that we would predict a different coverage type than is there currently, we should predict that that area is about to go through a severe ecological change. This will give administrators and rangers a chance to prepare for major changes in the forest's wildlife. Unfortunately, this application is difficult to test for directly, so we will settle for predicting the classes as is. Additionally, since we will be using this to test for changes in the environment, we will care as much about false negatives as false positives, since the precise classification will inform whether or nota change is correctly detected.\n",
    "\n",
    "This of course brings into question what we might use as a suitable baseline. We will see in the exploratory stages of the analysis that the distribution of cover type changes significantly between wilderness areas. We will use this to derive our baseline, which will predict the most frequent cover type for each wilderness area. For our algorithm to be considered as successfully fulfilling our task, it should be able to beat this baseline to within a statistically significant margin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much of the analysis in this notebook, including the above description, follows from [work completed for the previous project](https://github.com/carterkoehler/evaluation-and-mlp) on using Multi-Layer Perceptrons. More extensive visualizations of the feature distributions and other aspects of the dataset can be found there. Only ones that are directly applicable to the current analysis will be reproduced here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = 10, 8\n",
    "rcParams['axes.grid'] = True\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pprint import pprint\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Input\n",
    "from keras.layers import Embedding, Flatten, Merge, concatenate\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(os.pardir, 'data', 'covtype.csv')\n",
    "df_cov = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Picking Evaluation Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
